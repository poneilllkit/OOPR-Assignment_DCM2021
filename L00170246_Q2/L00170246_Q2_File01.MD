<div id="top"></div>


<!-- PROJECT LOGO -->
<br />
<div align="center">

  <h3 align="center">L00170246_Q2</h3>

  <p align="center">
    Continous Assessment 01
    <br/>
  </p>
</div>



<!-- TABLE OF CONTENTS -->
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#about-the-project">About The Project</a>
      <ul>
        <li><a href="#built-with">Built With</a></li>
      </ul>
    </li>
    <li>
      <a href="#getting-started">Getting Started</a>
      <ul>
        <li><a href="#prerequisites">Prerequisites</a></li>
        <li><a href="#installation">Installation</a></li>
      </ul>
    </li>
    <li><a href="#usage">Usage</a></li>
    <li><a href="#roadmap">Roadmap</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
    <li><a href="#acknowledgments">Acknowledgments</a></li>
  </ol>
</details>



<!-- ABOUT THE PROJECT -->
## About The Task

[![](/Users/pierceoneill/Desktop/OOPR Assignment DCM2021/L00170246_Q2/Screenshots/L00170246_Q2_img01.png)](https://example.com)

Code: Using Python on your host (windows) pc scrape the Apache 2 page you just
created (or LYIT web page) and parse it minimally for later processing.

As I have used BeautifulSoup on a previous assignment on a different course, I decided to try use Scrapy. 

Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival.

<p align="right">(<a href="#top">back to top</a>)</p>






<!-- GETTING STARTED -->
## Set up your system

Scrapy supports both versions of Python 2 and 3.

### 1. Install Scrapy
   ```sh
   pip install scrapy
   ```
#### 2. Scrapy Shell

Scrapy provides a shell of its own that you can use to experiment. To start the scrapy shell in your command line type:
   ```sh
   scrapy shell  
   ```
   
### 3. Fetch
    
To run the crawler in the shell type:
   ```sh
   fetch("https://www.lkit.ie")
   ```
   [![](/Users/pierceoneill/Desktop/OOPR Assignment DCM2021/L00170246_Q2/Screenshots/L00170246_Q2_img02.png)](https://example.com)
   
When you crawl something with scrapy it returns a “response” object that contains the downloaded info.
    

### 4. view(response)
    
   ```js
   view(response)
   ```
   
   [![](/Users/pierceoneill/Desktop/OOPR Assignment DCM2021/L00170246_Q2/Screenshots/L00170246_Q2_img03.png)](https://example.com)

This command will open the downloaded page in your default browser.



### 5. print response.text
    
   ```js
   print response.text
   ```
   
   [![](/Users/pierceoneill/Desktop/OOPR Assignment DCM2021/L00170246_Q2/Screenshots/L00170246_Q2_img04.png)



### 6. Extracting Information

That’s a lot of content but not all of it is relevant. Scrapy provides ways to extract information from HTML based on css selectors like class, id etc. 

 
### 7. Creating a scrapy project
    
Let’s exit the scrapy shell first and create a new scrapy project:

   ```js
   scrapy startproject L00170246_Q2File01
   ```


### 8. Creating a custom spider
    
Let’s change directory into our first scraper and create a basic spider “l00170246_Q2_File01” :

   ```js
   scrapy genspider l00170246_Q2_File01 lkit.ie
   ```
This will create a new spider “L00170246_Q2_File01.py” in the spiders/ folder with a basic template:

[![](/Users/pierceoneill/Desktop/OOPR Assignment DCM2021/L00170246_Q2/Screenshots/L00170246_Q2_img05.png)


### 9.  Creating a custom spider
    
Let’s exit the scrapy shell first and create a new scrapy project:

   ```js
   scrapy startproject L00170246_Q2File01
   ```


<p align="right">(<a href="#top">back to top</a>)</p>

<!-- CONTACT -->
## Contact

Your Name - [@your_twitter](https://twitter.com/your_username) - email@example.com

Project Link: [https://github.com/your_username/repo_name](https://github.com/your_username/repo_name)

<p align="right">(<a href="#top">back to top</a>)</p>



